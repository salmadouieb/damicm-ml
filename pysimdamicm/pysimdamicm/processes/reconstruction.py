from pysimdamicm.processes.detector_response import DigitizeProcess as ReconstructionProcess
from pysimdamicm.io.data_formats import Cluster
from pysimdamicm.utils.units import Units
u = Units()

import numpy as np
import numpy.ma as ma
import pandas as pd
from scipy.spatial.distance import cdist
from scipy.spatial import KDTree
from scipy.ndimage import label,find_objects
import time
from astropy.io import fits
import warnings
warnings.simplefilter('ignore', category=fits.verify.VerifyWarning)
from matplotlib import pyplot as plt

# deep copy for dictionaries
import copy
#ReconstructionProcess.__doc__ = """Abstract class for reconstruction used to process RAW data (signal obtained
#    from the detector, either SIM or real data)
#    """

##### module DEBUG VARIABLES
__verbose__ = False

###############################################################################################
#####       Cluster Finder PROCESS
###############################################################################################
class ClusterFinder(ReconstructionProcess):
    """Class to find cluster from the raw signal (hits/pixels)

    Attributes
    ----------
    method : int
        algorithm number to be used to find the clusters: 1-single-linkage clustering

    max_nearest_neighbor : int
        For the 'single-linkage clustering' algorithm is the maximum distance between two
        non `zero-charge` pixels of the same cluster. 

        `zero-charge` pixel: the charge of the pixel is below the **threshold**

        For the default value of `max_nearest_neighbor` (2 pixels) between two pixels 
        with non `zero-charge` one `zero-chage` pixel is allowed (see illustration below).

        `zero-charge` pixel: the charge of the pixel is below the **threshold**

        In this illustration, X represents pixels with `zero-charge`, and O pixels with
        charge>threshold:
        
        ::

            1   XXOOOXXXX
            2   XXXOOXXXX
            3   XXXXXOOXX
            4   XXXXXXXXX
            5   XXXXXXOXX

        With a max_nearest_neighbor of 2 pixels, :obj:`ClusterFinder` will classified all charged pixels 
        (i.e. all **O**) under the same cluster id; however if max_nearest_neighbor is 1 pixel, the algorithm 
        will end up with two clusters:
       
        ::

            1   XXOOOXXXX
            2   XXXOOXXXX
            3   XXXXXOOXX

        and

        ::

            5   XXXXXXOXX

        as two independent clusters.

    .. warning::

        threshold, minimum pixel charge accepted as ionized signal (henceforth included for the finding cluster algorithm)
        Those pixels above this threshold are obtained by :obj:`pysimdamicm.reconstruction.SignalPatternRecognition`
   
    """

    __sequence_id__ = 500
    __name__ = 'ClusterFinder'

    __spatial_metrics__='euclidean'
    __precission__=10
    __verbose__ = False
    __display__ = False
    save_plots = False
    save_img = False

    def __init__(self):
        super().__init__()

        # RUNNING ONLY ONCE PER IMAGE
        self._per_amp = True
        self.__DEBUG__ = False
        
        # PARAMETERS FOR THE SIGNAL PATTER ALGORITHM
        #############################################################################
        self.spr_threshold = None
        self.spr_image     = "mean_compressed_pedestal_subtracted_e"
        self.spr_sigma_mean = True
        # parameters two ignore certain rows and columns
        self.skip_rows = []
        self.skip_cols = []
        # speed up clusterization
        self.only_cls_seed = False
        
        # calculate the STD by fitting a gaussian to the cluster energy profile
        self.get_fitted_STD = True

        # Parameters related to the halo estudies
        #self.DEBUG_HALO = False
        #self.dohalo = False
        #self.halo_qmin = 0.75
        #self.halo_qmax = 1.65
        #self.halo_radius_min = 1
        #self.halo_radius  = 100
        
        # this parameters allow to get the energy threshold and compute ncut from this value. 
        # Energy threshold depence with image number is hardcoded 
        # The single electron resolution is given as CSV file, generated by the FitDarkCurrentPerRow process
        self.ismoskita = [False,None]
        
        # try to speed up clusterizatoin by allowing big images to use method 1, which is faster 
        #       and has the ability to define a maximum distance between pixels within the cluster, 
        #       which allow to have zero-charge pixels btw pixels of signal
        # If this is set to True, the BIG image in ROWS will be splitted, and execute clusterization will
        #   be done in a set of "smaller images", but using the function self.skip_rows
        # IMPORTANT: only valid for method == 1
        self.split_image_in_rows = False
        self.min_length = 500
        self.consecutive_ones = 10
        self.qmax_to_split_in_rows = 2.5
        self.hot_cols_tosplit = []

        self.__units__.update({
            "spr_threshold":u.ADC,"spr_image":1,'spr_sigma_mean':1,
            "skip_rows":1,"skip_cols":1, "only_cls_seed":1,
            "__DEBUG__":1,"get_fitted_STD":1,
            "ismoskita":1, 
            "split_image_in_rows":1,
            "min_length":1,
            "consecutive_ones":1,
            "qmax_to_split_in_rows":1,
            "hot_cols_tosplit":1
                })

        # PARAMETERS FOR THE CLUSTER PROCESS ITSELF
        #############################################################################
        self.method=int(1)
        self.max_nearest_neighbor=int(2)*u.pixel

        self.radius_of_acceptancy=self.max_nearest_neighbor*u.pixel

        self.__units__.update({"method":int(1),"max_nearest_neighbor":u.pixel,"radius_of_acceptancy":u.pixel,"__sequence_id__":1,"__verbose__":1})

    @property
    def radius_of_acceptancy(self):
        """Euclidian distance of two pixels spaced **max_nearest_neighbor** pixels apart

        """
        return self.__radius_of_acceptancy

    @radius_of_acceptancy.setter
    def radius_of_acceptancy(self,N):
        self.__radius_of_acceptancy = np.sqrt(N**2.0+N**2.0)+0.0000001

    def find_split_indices(self, array, min_length=500, consecutive_ones=10):
        split_indices = []
        i = 0 
        while i < len(array) - min_length:
            # Check if current value is 1 and the following 'consecutive_ones' values are also 1
            if array[i] == 0 and all(array[i + j] == 0 for j in range(1, consecutive_ones + 1)):
                # Check if the length of the current sub-array is at least 'min_length'

                if i >= min_length:
                    split_indices.append(i)
                    # Move the index forward by 'min_length'
                    i += min_length
                else:
                    # Move to the next index
                    i += 1
            else:
                # Move to the next index
                i += 1
        
        return split_indices
   
    def execute_process(self,hits):
        """Method to search for cluster in a given collection of hits

        Parameters
        ----------
        hits : :obj:`pysimdamicm.utils.data_foramts.G4HitCollection`

            A collection of hits (subset of hits from the geant4
            simulations) with at least the following attributes: x_pixel and y_pixel.

            
        Returns
        -------
        hits : :obj:`pysimdamicm.utils.data_foramts.G4HitCollection` 
            The **same input hits object**, with two extra attributes:

                a) **cluster_mask** : a dictionary of boolean masks, one for each found cluster
                b) **Ncls** : total number of clusters within the hits collection

        """

        # APPLY FIRST THE SIGNAL PATTER RECOGNITION ALGORITHM TO SET ALL NEEDED PARAMETERS
        if self.spr_threshold is not None:
            if self.ismoskita[0]:
                self.df_ismoskita = pd.read_csv(self.ismoskita[1])
                self._spr_threshold = copy.deepcopy( self.spr_threshold )
            
            # apply simple energy threshold
            self.execute_simple_threshold_cut(hits)
        
        if self.split_image_in_rows:
            print("\n- Clusterization is done in splitted images:")
            # find indices to split the image into smaller ones
            
            #exclude hot columns if known
            Nrows_tosplit,Ncols_tosplit =  hits._image_to_find_clusters_.shape
            mask_tosplit = np.zeros((Nrows_tosplit,Ncols_tosplit)).astype(bool)
            
            for c in self.hot_cols_tosplit:
            	if type(c)==list:
                    for ci in range(c[0],c[1]+1):
                    	try:
                    	    mask_tosplit[:,ci] = True
                    	except IndexError:
                            print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(ci,maskmask_tosplit.shape[1]))
            	else:
                    try:
                    	mask_tosplit[:,c] = True
                    except IndexError:
                    	print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(c,maskmask_tosplit.shape[1]))
                    
            image_tosplit = ma.masked_array(hits._image_to_find_clusters_, mask=mask_tosplit)
            maxQrow = np.max(image_tosplit > self.qmax_to_split_in_rows, axis=1).astype(int)
            #maxQrow = np.max(hits._image_to_find_clusters_ > self.qmax_to_split_in_rows, axis=1).astype(int)
            
            # min_length will be compared with the index position within the array, which starts from 0!
            split_indices = self.find_split_indices(maxQrow,self.min_length-1,self.consecutive_ones)
            # appends first and last index
            split_indices.append( 0 )
            split_indices.append( hits._image_to_find_clusters_.shape[0]-1 )
            indx = sorted(split_indices)
            # the image will be splitted in the following tuples:
            consecutive_tuples = [(indx[i], indx[i+1]) for i in range(len(indx) - 1)]
                        
            # copy the raw skip_row parameter
            _skip_rows = copy.deepcopy(self.skip_rows) if type(self.skip_rows)==dict else self.skip_rows.copy()
            
            # rcursive execute_process modifing the regions on rows to be masked
            for idx,(minRow,maxRow) in enumerate(consecutive_tuples):
                self.skip_rows = copy.deepcopy(_skip_rows[hits.execute_process_in_amp]) if type(_skip_rows)==dict else _skip_rows.copy()
                if minRow != 0:
                    self.skip_rows.append([0,minRow]) 
                if maxRow != max(indx):
                    self.skip_rows.append([maxRow+1,max(indx)])
                
                print("----- ")
                print(f"- Clusterizing row region: {minRow}:{maxRow}, apply row mask skip_rows: {self.skip_rows}")
    
                # get the energy threshold for moskita data: which depends on the image number
                if self.ismoskita[0]:
                    self.get_threshold_for_moskita_data(hits,idx)

                # apply simple energy threshold
                self.execute_simple_threshold_cut(hits)
                # find clusters in the selected region
                self.execute_process_clusterization(hits)
                # append Cluster objects to list of clusters
                self.get_cluster_object_list(hits)
   
        else:
            # find clusters in the selected region
            self.execute_process_clusterization(hits)
            
            # append Cluster objects to list of clusters
            self.get_cluster_object_list(hits)

        ### add distance to the closest cluster
        self.get_closest_cluster(hits)

    def get_threshold_for_moskita_data(self,hits,idx):
        
        try:
            ### update the threshold
            self.spr_threshold.update({f"{hits.execute_process_in_amp}": 
                [self.df_ismoskita.resolution[idx], self._spr_threshold[f"{hits.execute_process_in_amp}"][1], self._spr_threshold[f"{hits.execute_process_in_amp}"][2]]}
                )
        except KeyError:
            raise(f"KeyError: Has the same length the splitted image and the input csv?")

        return
    
    def execute_simple_threshold_cut(self,hits):
        """Apply a simple energy threshold cut, to select those pixels with pixel 

            .. math::
               Q_{ij} > Q_{T}

           where :math:`Q_{T}` is attribute **threshold**
        """
        if hasattr(hits,'noise'):
            #print("  Input threshold for SPR: {} e- (i.e. {} eV)".format(self.spr_threshold, self.spr_threshold*u.e2eV))
            hits.get_total_signal(self.spr_threshold*u.e2eV)
            if hits.x_pixel_noise.size == 0:
                hits.killed = True
        else:
            if hits.isdata:
                print("")
                print(f"Process <Signal Patter Recognition>: simple threshold cut on image {self.spr_image} and amplifier/ccd {hits.execute_process_in_amp}")

                if type(self.spr_threshold)==list:
                    threshold = self.spr_threshold.copy()
                elif type(self.spr_threshold)==dict:
                    threshold = self.spr_threshold[hits.execute_process_in_amp].copy()
                else:
                    msm = "Theshold parameter is not well defined. 'threshold'  must be a list "
                    msm += "if only one amplifier is reprocessed) or a dictionary with a list for each amplifier"
                    raise AttributeError(msm)
                
                ### THE SIGMA VALUE (FIRST ARGUMENT IN THE LIST) CAN BE: 
                #       None --> use the values computed by Pedestal subttraction
                #       float --> use the value given by the user
                ###########################################################################################################
                if type(threshold[0]) is str:
                    ADC2e = hits.ADC2e[hits.execute_process_in_amp] if hasattr(hits,'ADC2e') else u.ADC2e
                    threshold[0] = hits.image_header[threshold[0]] / ADC2e*u.e2eV
                    print(f"Using sigma value the HEADER: {threshold[0]} eV [with ADC2e={ADC2e}, e2eV={u.e2eV}]")
                    threshold.append( 0.0 )
                elif threshold[0] is None:
                    # sigma will be obtained as mean or median
                    npfunc = np.nanmean if self.spr_sigma_mean else np.nanmedian

                    #### estimate a single value using the full set of pedestals
                    sigma_list = []
                    # use the pedestal values related to the given amplifier
                    pedestal_sigma = hits.pedestal_sigma[hits.execute_process_in_amp]

                    # pedestal subtraction can have row/column subtraction
                    for ax in pedestal_sigma.keys():
                        # add all values of the pedestal in rows, but also in cols (if they are)
                        sigma_list.extend( np.array(pedestal_sigma[ax]).flatten().tolist() )

                    ### get calibration which can be amplifier dependent
                    if hasattr(hits,'ADC2e'):
                        ADC2e = hits.ADC2e[hits.execute_process_in_amp]
                    else:
                        ADC2e = u.ADC2e
                    threshold[0] = npfunc(sigma_list)/ADC2e*u.e2eV

                    #### add STD as the error
                    threshold.append(np.nanstd(sigma_list)/ADC2e*u.e2eV)
                    print(f" - Sigma for SPR: {npfunc(sigma_list)} ADUs ({ADC2e} ADU/e-, {u.e2eV} eV/e-), i.e. {np.round(threshold[0],3)} eV")
                else:
                    # assumed to be in electron units
                    print(f" - Sigma for SPR: {threshold[0]} e- (with {u.e2eV} eV/e-)")
                    threshold[0] = threshold[0]*u.e2eV
                    # no noise for the sigma value is given
                    threshold.append( 0.0 )


                ### image in units of eV!!!
                print(f"  - Used threshold for SPR: {threshold[0]} eV, n_min={threshold[1]}, n_sed={threshold[2]}, std_sigma={threshold[3]} eV")
                
                hits.apply_simple_threshold_cut(threshold,self.spr_image,skip_rows=self.skip_rows,skip_cols=self.skip_cols)
            else:
                raise RuntimeError("SPR is not implemented for images without noise! Set dark current or electronic noise, or remove spr_threshold")


    def execute_process_clusterization(self,hits):
        # APPLY NOW THE CLUSTER ALGORITHM WITH THE SELECTED PIXELS
        #################################################################################################
        self.radius_of_acceptancy=self.max_nearest_neighbor*u.pixel
        if hasattr(hits,'noise') and not hasattr(hits,'Edep_pixel_img_noise'):
            hits.get_total_signal()
        else:
            if not hits.isdata: 
                # noise is not simulated, but pixel saturation?
                if hasattr(hits,"pix_saturation") and hits.pix_saturation>0:
                    Edep=getattr(hits,"Edep{}".format(hits.__attr_to_clusterize__))
                    setattr(hits,"Edep_pixels_MCT".format(hits.__attr_to_clusterize__),Edep.copy())
                    pix_sat_mask=Edep>hits.pix_saturation
                    ## create a boolean pixel array to keep track of saturated pixels
                    Edep_map_sat=np.zeros_like(Edep,dtype=bool)
                    Edep_map_sat[pix_sat_mask]=True
                    setattr(hits,"Edep_map_sat",Edep_map_sat)
                    ## set pixdels with larger pixel charge to the maximum value
                    Edep[pix_sat_mask]=hits.pix_saturation
                    setattr(hits,"Edep{}".format(hits.__attr_to_clusterize__),Edep)

        if self.method == 1:
            self.find_clusters_kradius_neighbor(hits)
        elif self.method == 0:
            self.find_clusters_ndimage_label(hits)

    def get_cluster_object_list(self,hits):
        if not hasattr(hits,'evt_clusters'):
            setattr(hits,'evt_clusters',[])
            setattr(hits,'Nclusters',0)
            setattr(hits,'evt_clusters_in_amp',[])
            # to get the closest cluster distance
            setattr(hits,'_PosX',[])
            setattr(hits,'_PosY',[])
            setattr(hits,'_hasseed',[])
        
        # print("Collecting the clusters ... ")
        n_run   = hits.n_run if hasattr(hits,'n_run') else 0
        n_image = hits.n_image if hasattr(hits,'n_image') else 0
        if hits.isdata:
            hits.get_compatibility_with_ClusterObject(n_run,n_image)
        
        for i,mask in hits.cluster_mask.items():
            # in which amplifier
            x = (getattr(hits,"x{}".format(hits.__attr_to_clusterize__))[mask])
            y = (getattr(hits,"y{}".format(hits.__attr_to_clusterize__))[mask])
            
            if hits.isdata:
                amp = self.in_which_amplifier(
                        getattr(hits,"x{}".format(hits.__attr_to_clusterize__))[mask], 
                        getattr(hits,"y{}".format(hits.__attr_to_clusterize__))[mask], hits.amplifier)
            else:
                amp = "SIM"
            
            hits.evt_clusters.append(Cluster(i,hits,mask))
            hits.evt_clusters[-1].get_cluster_properties(__DEBUG__=self.__DEBUG__,get_fitted_STD=self.get_fitted_STD)
            # override cluster_id (needed for splitted image mode)
            hits.Nclusters +=1
            hits.evt_clusters[-1].cluster_id = hits.Nclusters
            hits.evt_clusters_in_amp.append(amp)
            hits._PosX.append( hits.evt_clusters[-1].PosX )
            hits._PosY.append( hits.evt_clusters[-1].PosY )
            try:
                hits._hasseed.append( hits.evt_clusters[-1].has_seed )
            except AttributeError:
                pass
           
        return
    
    @staticmethod
    def in_which_amplifier(x,y,amp_dict):

        for amp_name in amp_dict.keys():
            amp = amp_dict[amp_name]
            in_amp = 0
            if min(y)>=amp['rows'][0] and max(y)<=amp['rows'][1]:
                in_amp +=1
            if min(x)>=amp['cols'][0] and max(x)<=amp['cols'][1]:
                in_amp +=1

            if in_amp==2:
                return amp_name

        return None

    def find_clusters_ndimage_label(self,hits):
        """
        """
        # matrix to point direction in which direction to look for "vecinos"
        #   up, down, left, right, but also in diagonal
        conections =  [
                [1,1,1],
                [1,1,1],
                [1,1,1]
                ]

        # read the image to find clusters, in case data is used,
        # or create an image from the x and y positions
        x_pixel=getattr(hits,"x{}".format(hits.__attr_to_clusterize__))
        y_pixel=getattr(hits,"y{}".format(hits.__attr_to_clusterize__))

        if hasattr(hits,'_image_to_find_clusters_'):
            image = hits._image_to_find_clusters_

            # create an image with only those pixels that are cluster seed
            seed_mask = np.zeros_like(image).astype(bool)
            seed_mask[y_pixel,x_pixel] = hits.pixel_cluster_seed
        else:
            image = np.zeros((y_pixel.max()+1,x_pixel.max()+1))
            # ADD "FAKE" charge to these pixels
            image[y_pixel,x_pixel] = 10000

        
        # digitalize the image: 1-pixel to consider, 0-noise
        img = np.where(image>0.0, 1, 0) 

        # label all clusters in image: 1,2,3...n
        img_cls_labels, n_clusters = label(img,conections)

        #### for each cluster in img_cls_labels, and slice object will be given
        #       (y_slice, x_slice)
        cluster = find_objects(img_cls_labels)
        
        x_pixel_list = []
        y_pixel_list = []
        found_clusters = {}
        
        if self.only_cls_seed:
            __pixels_to_clusterize = list(set(img_cls_labels[seed_mask]))
        else:
            __pixels_to_clusterize = np.arange(1,n_clusters+1)

        for i in __pixels_to_clusterize:
            y,x = np.where(img_cls_labels == i)
            found_clusters[i] = slice(len(x_pixel_list),len(x_pixel_list)+len(x))
            for xi,yi in zip(x,y):
                x_pixel_list.append(xi)
                y_pixel_list.append(yi)

        # convert list of arrays into single list
        setattr(hits,"x{}".format(hits.__attr_to_clusterize__),np.array(x_pixel_list))
        setattr(hits,"y{}".format(hits.__attr_to_clusterize__),np.array(y_pixel_list))
        if hasattr(hits,'_image_to_find_clusters_'):
            hits.pixel_charge = hits._image_to_find_clusters_[y_pixel_list,x_pixel_list]

        # add as anttribute the dictionary with all mask
        setattr(hits,'cluster_mask',found_clusters)
        setattr(hits,'Ncls', len(__pixels_to_clusterize))
        

    def find_clusters_kradius_neighbor(self,hits):
        """'single-linkage clustering' algorithm to find clusters
        
        Find a collection of pixels (xy-plane) that at least have a non-zero-charge 
        pixel within a circle of radius **radius_of_acceptancy** pixels.

        """
        t1 = time.time() 
        #### ---- last process before Clusterization is given by __attr_to_clusterize__
        x_pixel=getattr(hits,"x{}".format(hits.__attr_to_clusterize__))
        y_pixel=getattr(hits,"y{}".format(hits.__attr_to_clusterize__))
        
        #### Compute the euclidian distance for each pair of pixels in hits
        points = np.array(list(zip(y_pixel,x_pixel)))
        if y_pixel.size==0 and x_pixel.size==0:
            cont = False
            found_clusters = {}
            setattr(hits,'cluster_mask',found_clusters)
            setattr(hits,'Ncls',0)
            return

        try:
            matrix_distance = cdist(points,points,self.__spatial_metrics__)
        except ValueError:
            msm="The size of the sensitive detector is {} by {} pixels, is that correct?".format(
                    u.ccd_shape[0],u.ccd_shape[1])
            raise RuntimeError("\x1b[31m {} \x1b[m".format(msm))
        except MemoryError:
            msm="Too many pixels for the Cluster Finder Algorithm: try to use "
            msm+=" SignalPatternRecognition with a more restrictive threshold\n"
            msm+=" Or run FindCluster with method=0."
            raise MemoryError("\x1b[31m {} \x1b[m".format(msm))

        #### Two points within a circle with a radius less than radius_of_acceptancy
        ####    belongs to the same cluster
        #### Given a kradius, prepare the mask to BINARIZE the distance mattrix
        matrix_distance_masked = np.ma.masked_where(matrix_distance>self.radius_of_acceptancy,matrix_distance)

        #### Ignore values out of the radius_of_acceptancy, and accept the rest
        matrix_distance_masked.data[matrix_distance_masked.mask] = 0.0
        matrix_distance_masked.data[np.logical_not(matrix_distance_masked.mask)] = 1.0

        #### Search for clusters:
        ## List of points belong to the same cluster, 
        ## where the key is the proxy of the cluster (first element)
        cluster = {}

        ## Auxiliary object of not used ROWs (vertex not added)
        row_is_not_added = np.array( [True for i in range(len(points))] )

        cont = True
        row_not_finished = True
        row = 0
        while cont:
            while row_not_finished:
            #for row in range(len(points)):
                if row_is_not_added[row]:
                    # new cluster found, add all the vertexs from its ROW
                    cluster[row] = set( np.where(matrix_distance_masked.data[row]>0.0)[0] )
                    # delete ROW from auxiliary to avoid re-reading VERTEXS from the same row
                    row_is_not_added[row] = False

                    # for all his VERTEXS search for new connections (i.e. adjacents of adjacents,
                    # farther points, but still connected)
                    row_vert_to_add = list(np.where(matrix_distance_masked.data[row]>0.0)[0])[1:]
                    # if the ROW does not contain any other vertex, i.e. a cluster with one point!
                    try:
                        ind_row_vert = 0
                        row_vert = row_vert_to_add[ind_row_vert]
                        same_cluster = True
                    except IndexError:
                        same_cluster = False

                    while same_cluster:
                        if row_is_not_added[row_vert]:
                            # adjacents from vertex row index row_vert
                            inds_from_row_vert = set(np.where(matrix_distance_masked.data[row_vert]>0.0)[0])
                            # add these new vertexs to the auxiliary *row_vert_to_add* list, and to its
                            # cluster
                            cluster[row] = cluster[row].union( inds_from_row_vert )
                            row_vert_to_add = row_vert_to_add + sorted(list(inds_from_row_vert-set(row_vert_to_add)))
                            # delete ROW from auxiliary list to avoid re-reading VERTEXS from the same
                            # row 
                            row_is_not_added[row_vert] = False

                        ind_row_vert+=1
                        if ind_row_vert >= len(row_vert_to_add) or len(points[row_is_not_added]) <1:
                            break
                        row_vert = row_vert_to_add[ind_row_vert]


                try:
                    row = np.where(row_is_not_added)[0][0]
                except IndexError:
                    row_not_finished = False

            if not len(points[row_is_not_added])>0:
                cont = False
            
        #self.found_clusters = {}
        found_clusters = {}
        ### Create an array with all pixels masked
        mask_cluster_kindex = np.ones(x_pixel.size, dtype=bool)
         
        kindex = 0
        for kid,inds in cluster.items():
            kindex+=1
            ### Create an array with all pixels masked            
            mask_cluster_kindex = np.zeros(x_pixel.size, dtype=bool)
            ### un-mask pixels from this cluster
            mask_cluster_kindex[list(inds)]=True

            ### store the mask for the cluster id kindex
            found_clusters[kindex] = mask_cluster_kindex
        
        setattr(hits,'cluster_mask',found_clusters)
        setattr(hits,'Ncls',kindex)
               
        hits.time_cf = time.time()-t1

    def get_closest_cluster(self,hits):
        
        if len(hits.evt_clusters)<=1:
            return
        if len(hits._hasseed)==0:
            return

        PosX = np.array(hits._PosX)
        PosY = np.array(hits._PosY)
        hasseed = np.array(hits._hasseed)
       
        # Get the closest cluster (only for has_seed)
        for idx in range(hits.Nclusters):
            if hits.evt_clusters[idx].has_seed:
                distances = np.sqrt((PosX - hits.evt_clusters[idx].PosX)**2.0 + (PosY - hits.evt_clusters[idx].PosY)**2.0)
                # exclude himself from the lists
                mask = np.logical_and( PosX != hits.evt_clusters[idx].PosX, PosY != hits.evt_clusters[idx].PosY )
                mask = np.logical_and( mask, hasseed )
                distances = np.where(mask,distances,np.inf)
                setattr(hits.evt_clusters[idx],'closest_cls_dist',   float(distances[np.argmin(distances)]))
                setattr(hits.evt_clusters[idx],'closest_cls_dist_X', float(abs(PosX[np.argmin(distances)]-hits.evt_clusters[idx].PosX)))
                setattr(hits.evt_clusters[idx],'closest_cls_dist_Y', float(abs(PosY[np.argmin(distances)]-hits.evt_clusters[idx].PosY)))
                setattr(hits.evt_clusters[idx],'closest_cls_id',     float(np.argmin(distances)+1))
            else:
                setattr(hits.evt_clusters[idx],'closest_cls_dist',   float(-1.0))
                setattr(hits.evt_clusters[idx],'closest_cls_dist_X', float(-1.0))
                setattr(hits.evt_clusters[idx],'closest_cls_dist_Y', float(-1.0))
                setattr(hits.evt_clusters[idx],'closest_cls_id',     float(-1.0))

        return

###################################################################################################################
#### class to build a mask around all clusters
###################################################################################################################
class BuildClusterMask(ReconstructionProcess):
    """
    """
    __name__ = 'BuildClusterMask'
    __sequence_id__ = 550

    def __init__(self):
        super().__init__()
        
        self._per_amp = False

        self.N_col_pre  = 5
        self.N_col_post = 5
        self.N_row_pre  = 5
        self.N_row_post = 5
        
        self.mask_below_threshold = [False,0]
        self.cluster_box_E_min = 100.0
        self.cluster_size_min = 2
        self.cluster_E_min    = 0
        self.cluster_DX_min   = 1
        self.cluster_DY_min   = 1
        # to mask any column that belongs to a cluster with energy self.cluster_box_E_min
        self.mask_cluster_column = False
        self.mask_cluster_row    = False
        
        self.add_cluster_id = False
        self.qmax_threshold = 0.5

        # to apply a circular mask with radius sef.N_col_post
        self.circular_mask = False
        self.radius = 0

        self.hot_cols = []
        self.hot_rows = []

        self.__units__.update({ 'N_col_pre':1, 'N_col_post':1, 'N_row_pre':1, 'N_row_post':1,
            '__sequence_id__':1, 'cluster_size_min':1 , 'cluster_E_min':1, 
            'cluster_DX_min':1, 'cluster_DY_min':1, 'cluster_box_E_min':1, 'mask_cluster_column':1,
            'mask_cluster_row':1,'add_cluster_id':1, 'qmax_threshold':1,
            'hot_cols':1, 'hot_rows':1, "circular_mask":1, "radius":1, "mask_below_threshold":1} )
        
    def create_circular_mask(self,shape,center,radius):
        y, x = np.ogrid[:shape[0], :shape[1]]
        dist_from_center = np.sqrt((x - center[1])**2 + (y - center[0])**2)
        mask = dist_from_center <= radius
        return mask

    def execute_process(self,hits):
        """

        serial register (columns, x): h-clock direction (HCKDIRN: U,L)
        rows,y : vertical direction                     (VCKDIRN: 1,2)

        """
        print("Process <BuildClusterMask> INFO. Build a ndarray to mask all clusters and its surrounding pixels")
        
        # starting mask with only pixels in the active region of both amplifiers
        _Namp = list(hits.amplifier.keys())
        if len(_Namp)==1:
            print("  >>> readout using only one amplifer ")
            mask = ~hits.amplifier[_Namp[0]]['mask_image_active_region']
        elif len(_Namp)==2 and not hits.ACM:
            print("  >>> readout using two amplifers ")
            mask = np.logical_or(~hits.amplifier[_Namp[0]]['mask_image_active_region'],~hits.amplifier[_Namp[1]]['mask_image_active_region'])
        elif hits.ACM:
            print(f"  >>> ACM readout with {len(_Namp)} extensions")
            if len(_Namp)==1:
                mask = ~hits.amplifier[_Namp[0]]['mask_image_active_region']
            elif len(_Namp)==2:
                mask = np.logical_or(~hits.amplifier[_Namp[0]]['mask_image_active_region'],~hits.amplifier[_Namp[1]]['mask_image_active_region'])
            elif len(_Namp)>2:
                mask = np.logical_or(~hits.amplifier[_Namp[0]]['mask_image_active_region'],~hits.amplifier[_Namp[1]]['mask_image_active_region'])
                for _namp in _Namp[2:]:
                    mask = np.logical_or(mask, ~hits.amplifier[_namp]['mask_image_active_region'])
        else:
            raise RuntimeError("Readout with more than 2 amplifiers not supported yet!")
       

        Nrows,Ncols =  mask.shape
        if self.circular_mask:
            #setattr(hits,'circular_mask_clusters', np.zeros((Nrows,Ncols)))
            cmask = np.zeros((Nrows,Ncols)).astype(bool)

        # add cluster ID at a given image
        if self.add_cluster_id:
            cmask_ids = np.zeros((Nrows,Ncols)).astype(float)

        for i,(cls,amp) in enumerate(zip(hits.evt_clusters,hits.evt_clusters_in_amp)):
            #if len(cls.pixels_x)>1:
            #    print(cls.pixels_x-1,cls.pixels_y-1,np.round(cls.Energy*u.keV/u.eV/u.e2eV,0))

            check_Emin_condition = True
            if self.mask_below_threshold[0]:
                if cls.Energy*u.keV/u.eV <= self.mask_below_threshold[1]*u.e2eV:
                    # cluster energy below threshold should be masked, skip Emin conditioon this time
                    check_Emin_condition = False
                    
            if not cls.has_seed:
                continue
            
            # do not mask if the cluster has not a mininum size
            if cls.Npix<self.cluster_size_min:
                continue
            
            # do not mask if the cluster has not a minimum value for its energy 
            if check_Emin_condition:
                if cls.Energy*u.keV/u.eV <= self.cluster_E_min*u.e2eV:
                    continue
            ### 
            # do not mask if cluster size on the axis is smaller
            if cls.DX < self.cluster_DX_min:
                continue
            if cls.DY < self.cluster_DY_min:
                continue
            
            # information about the y and x positions comes from the Cluster object, where the
            # pixels starts on 1
            if cls.Energy*u.keV/u.eV > self.cluster_box_E_min*u.e2eV:
                N_col_pre  = self.N_col_pre
                N_col_post = self.N_col_post
                N_row_pre  = self.N_row_pre
                N_row_post = self.N_row_post
            else:
                ## if cluster has less energy than the Emin_box a pixel above and below (before and after) vertically and horizontally are masked too.
                N_col_pre  = 1
                N_col_post = 1
                N_row_pre  = 1
                N_row_post = 1
            
            Qmax = 0
            QmaxYX = (0,0)
            for y,x,E in zip(cls.pixels_y-1,cls.pixels_x-1,cls.pixels_E):
                if E<0.0:
                    print(x,y,E)
                
                if E>Qmax:
                    Qmax=E
                    QmaxYX=(y,x)

                if self.mask_cluster_column and (cls.Energy*u.keV/u.eV>self.cluster_box_E_min*u.e2eV):
                    col_slice = slice(x, min(x+N_col_post,Ncols))
                    mask[:,col_slice] = False
                elif self.mask_cluster_row and (cls.Energy*u.keV/u.eV>self.cluster_box_E_min*u.e2eV):
                    #print(f"Masking rows from cluster with energy: {cls.Energy*u.keV/u.eV}>{self.cluster_box_E_min*u.e2eV}")
                    mask[y,:] = False
                else:
                    ###### readout direction depends on the amplifier
                    ########################################################################################
                    # XXX as we keep data as it is, we must take care of that here ...
                    if len(_Namp)==1 or hits.ACM:
                        ###### readout with only one amplifier per extension
                        ###### ACM readout with only one amplifier per extension, 
                        ######  but several ext corresponds to different CCD in the same module, all readout in the same direction
                        col_slice = slice(max(0,x-N_col_pre), min(x+N_col_post,Ncols)+1)
                    elif len(_Namp)==2:
                        ###### readout with two amplifier per extension: readout left (L) and right (U)
                        if amp=="L":
                            # readout is done in increasing order of the pixel id
                            col_slice = slice(max(0,x-N_col_pre), min(x+N_col_post,Ncols)+1)
                        elif amp=="U":
                            # readout is done in inverse order
                            col_slice = slice(max(0,x-N_col_post), min(x+N_col_pre,Ncols)+1)

                    # readout is in the same direction in both amplifers
                    row_slice = slice(max(0,y-N_row_pre), min(y+N_row_post,Nrows)+1)
                    
                    mask[row_slice,col_slice] = False
            
                if self.add_cluster_id:
                    # self.qmax_threshold can be used as a fraction of charge, i.e. values between 0 and 1, 
                    #       or just an energy value in units of electrons
                    if self.qmax_threshold>1:
                        # assumed is given in electron units
                        add_pixel = E*u.keV/u.e2eV > self.qmax_threshold
                    else:
                        # is given as frction of charge with respect to 
                        add_pixel = E/cls.Qmax > self.qmax_threshold

                    if add_pixel:
                        # Add pixel charge and id if the fraction of energy is larger than a given value
                        # with respect the point with the maximum energy deposition, not the total energy
                        cmask_ids[int(y),int(x)] = cls.cluster_id*1E10 + E*u.keV/u.e2eV

            # circular mask only from the center of the cluster: center means averaged position 
            if self.circular_mask and Qmax>0.0:
                cmask = np.logical_or(cmask,create_circular_mask(cmask.shape,QmaxYX),self.radius)
                

        setattr(hits,'mask_clusters_only',~mask.copy())
        if self.add_cluster_id:
            setattr(hits,'mask_clusters_ids',cmask_ids.copy())
            print(f"  >>> added {np.sum(cmask_ids>0)} encoded pixel charge (cluster_id x E10 + q_ij)")


        # ADD HOT COLS AND ROWS
        _hot_rows = self.hot_rows[hits.execute_process_in_amp] if type(self.hot_rows)==dict else self.hot_rows
        for r in _hot_rows:
            if type(r)==list:
                for ri in range(r[0],r[1]+1):
                    try:
                        mask[ri,:] = False
                    except IndexError:
                        print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(ri,mask.shape[0])) 
            else:
                try:
                    mask[r,:] = False
                except IndexError:
                    print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(r,mask.shape[0]))

        _hot_cols = self.hot_cols[hits.execute_process_in_amp] if type(self.hot_cols)==dict else self.hot_cols
        for c in _hot_cols:
            if type(c)==list:
                for ci in range(c[0],c[1]+1):
                    try:
                        mask[:,ci] = False
                    except IndexError:
                        print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(ci,mask.shape[1]))
            else:
                try:
                    mask[:,c] = False
                except IndexError:
                    print("WARNING: IndexError(Ignoring index {} is out of bounds for axis col with size {})".format(c,mask.shape[1]))
        
        # 1 as masked pixels (do not use them)
        setattr(hits,'mask_clusters',~mask.copy())
        # 1 as masked pixels
        if self.circular_mask:
            setattr(hits,'circular_mask_clusters',cmask.copy())

        
class ApplySelectionCuts(ReconstructionProcess):
    """Class to tag whenever a cluster is within the excluded region defined by the selection cuts

    """

    __sequence_id__ = 600
    __name__ = "ApplySelectionCuts"

    __verbose__ = False
    __display__ = False
    save_plots  = False
    save_img    = False

    def __init__(self):
        super().__init__()

        self._per_amp = False  

        self.cols = []
        self.rows = []
        
        # add __sequence_id__ in the units dictionary to allow the process manager to change the
        # default order in the process sequence
        self.__units__.update({"cols":1,"rows":1,"__sequence_id__":1})

    def execute_process(self,hits):
        """
        """
        # Check if any pixel from the clusters belongs to a hot row and column

        print("Process <ApplySelectionCuts> INFO. Identify clusters that fall into hot regions.")
        
        if hasattr(hits,"ACM") and hits.ACM:
            itype = "image_mean_compressed" if hasattr(hits,"image_mean_compressed") else hasattr(hits,"image_median_compressed")
            try:
                Nrows,Ncols = getattr(hits,itype).shape
            except AttributeError:
                if hasattr(hits,"mean_pedestal_subtracted"):
                    itype = "mean_pedestal_subtracted"
                    Nrows,Ncols = getattr(hits,itype).shape()
                else:
                    raise AttributeError(f"{self.__name__}: RawData has no attribute image_mean/median_compressed neitherr mean_pedestal_subtracted")
        else:
            Nrows,Ncols = hits.nrows,hits.ncols
        
        # MASK COLUMNS
        if type(self.cols)==dict:
            _cols_obj = self.cols[hits.execute_process_in_amp]
        else:
            _cols_obj = self.cols

        cut_cols = []
        for col in _cols_obj:
            if type(col)==list:
                for c in range(col[0],col[1]+1):
                    cut_cols.append(int(c))
            else:
                cut_cols.append(int(col))
        set_cols = sorted(set(cut_cols))
        setattr(hits,"in_hot_columns",np.zeros(Ncols).astype(bool))
        hits.in_hot_columns[set_cols] = True

        
        # MASK ROWS
        if type(self.rows)==dict:
            _rows_obj = self.rows[hits.execute_process_in_amp]
        else:
            _rows_obj = self.rows

        cut_rows = []
        for row in _rows_obj:
            if type(row)==list:
                for r in range(row[0],row[1]+1):
                    cut_rows.append(int(r))
            else:
                cut_rows.append(int(row))
        set_rows = sorted(set(cut_rows))
        setattr(hits,"in_hot_rows",np.zeros(Nrows).astype(bool))
        hits.in_hot_rows[set_rows] = True


###############################################################################################
#####       Create a FITS IMAGE TO BE USED AS "REAL" DATA
###############################################################################################
class CreateFitsImage(ReconstructionProcess):
    """Class to Create and Store a fits image

    """

    __sequence_id__ = 200
    __name__ = "CreateFitsImage"

    __verbose__ = False
    __display__ = False
    
    def __init__(self):
        super().__init__()
        
        self.blank_image = None
        self.n_events = 100
        
        self.__units__.update({"__verbose__":1,"n_events":1,'blank_image':1})
        
        ### private data memeber (user should not have access)
        self.n_evt_added = 0
        self.n_fits = 1
    
    @property
    def blank_image(self):
        return self.__blank_image
    @blank_image.setter
    def blank_image(self,val):
        if val is None:
            self.__blank_image = None
            return
        data = fits.getdata(val)
        self.__blank_image = data*u.ADC
        print("  Blank image is added: ")
        print("     overscan:  mean={} ADC, std={} ADC".format(
            np.mean(data[:,data.shape[1]-u.n_cols_overscan:]),
            np.std(data[:,data.shape[1]-u.n_cols_overscan:])))

    def execute_process(self,hits):
        """Create a CCD image and store it as a fits file
        """

        if hasattr(hits,'noise') and not hasattr(hits,'Edep_pixel_img_noise'):
            hits.get_total_signal()
        
        n_rows,n_cols = u.ccd_shape
        
        ### dictionary with the noise and the pure simulation: noise, signal and total
        if not hasattr(hits,'CCD_image'):
            raise AttributeError("Dark Current or Electronic noise should be active!")

        if not hasattr(self,'image'):
            self.image = hits.CCD_image['signal']/u.ADC2eV
        else:
            self.image += hits.CCD_image['signal']/u.ADC2eV

        self.n_evt_added +=1

        if self.n_events == self.n_evt_added:
            if self.blank_image is None:
                self.image = self.image + hits.CCD_image['noise']/u.ADC2eV
            else:
                #### input in ADC values
                self.image = self.image + self.blank_image

            self.build_header(hits)
            outfile = hits.outfile.replace(".root","_image_{}.fits".format(self.n_fits))
            self.SaveAsFits(outfile)

            ### setting attributes
            self.n_fits +=1
            self.n_evt_added=0
            del(self.image)


    def SaveAsFits(self,output,hdus=[],overwrite=True):
        ### header
        hdu_list = [fits.PrimaryHDU(data=self.image, header=self.header)]

	#### include other data
        if len(hdus)>0:
            for data in hdus[1:]:
                if dtype is not None:
                    data = data.astype(dtype)
                hdu_list.append(fits.ImageHDU(data=data))
    
        hdul = fits.HDUList(hdu_list)
        hdul.writeto(output,overwrite=overwrite)

    def build_header(self,hits):
        """
        """

        self.header = fits.Header({'SIMPLE':True})
        self.header['INFO'] = 'pysimdamim.processes.reconstruction.CreateFitsImage'
        self.header['INFILE'] =(hits.outfile.split("/")[-1],"Simulation input root file")
        self.header['SIMS'] = (False,"Data from simulations")
        self.header['NDCMS'] = 1
        #self.header['NAXIS1'] = self.image.shape[1]
        #self.header['NAXIS2'] = self.image.shape[0]
        #### simulated dark current
        try:
            self.header['DC']   = (hits.darkcurrent,'simulated dark current, e-/pix/s')
            self.header['TEXP'] = (hits.exp_time, 'simulated exposure time, s')
        except AttributeError:
            pass
        #### simulated electronic noise
        try:
            self.header['PED'] = (hits.pedestal,'simulated pedestal, e-')
            self.header['SIGMA'] = (hits.sigma,'simulated sigma, e-')
        except AttributeError:
            pass

    def __del__(self,hits):
        """
        """
        if self.blank_image is None:
            self.image = self.image + hits.CCD_image['noise']/u.ADC2eV
        else:
            #### input in ADC values
            self.image = self.image + self.blank_image

        self.build_header(hits)
        outfile = hits.outfile.replace(".root","_image_{}.fits".format(self.n_fits))
        self.SaveAsFits(outfile)
        print("     - closed")
        print("     - {} fits files have been recorded ".format(self.n_fits))
        print("     - each file contains {} (evt,ccd) simulated pairs ".format(self.n_events))
        print("     - output pattern file is: ", hits.outfile.replace(".root","_image_{}.fits\n"))
        
        

